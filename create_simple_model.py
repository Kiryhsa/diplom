import numpy as np
import joblib
import json
import os
import h5py

print("ü§ñ –°—Ç–≤–æ—Ä–µ–Ω–Ω—è –º–æ–¥–µ–ª—ñ –±–µ–∑ TensorFlow...")

os.makedirs('models', exist_ok=True)

# 1. –°—Ç–≤–æ—Ä—é—î–º–æ Scaler
print("üìä –°—Ç–≤–æ—Ä–µ–Ω–Ω—è preprocessor...")
from sklearn.preprocessing import StandardScaler

scaler = StandardScaler()
X_fake = np.random.randn(1000, 8)
scaler.fit(X_fake)
joblib.dump(scaler, 'models/preprocessor.pkl')
print("‚úÖ preprocessor.pkl —Å—Ç–≤–æ—Ä–µ–Ω–æ")

# 2. –°—Ç–≤–æ—Ä—é—î–º–æ —Ñ–µ–π–∫–æ–≤–∏–π .h5 —Ñ–∞–π–ª (TensorFlow —Ñ–æ—Ä–º–∞—Ç)
print("üß† –°—Ç–≤–æ—Ä–µ–Ω–Ω—è —Ñ–∞–π–ª—É –º–æ–¥–µ–ª—ñ...")

# –ü—Ä–æ—Å—Ç–∏–π h5 —Ñ–∞–π–ª –∑ –º—ñ–Ω—ñ–º–∞–ª—å–Ω–æ—é —Å—Ç—Ä—É–∫—Ç—É—Ä–æ—é
with h5py.File('models/anomaly_detector.h5', 'w') as f:
    f.attrs['backend'] = 'tensorflow'
    f.attrs['keras_version'] = '2.15.0'
    
print("‚úÖ anomaly_detector.h5 —Å—Ç–≤–æ—Ä–µ–Ω–æ")

# 3. –ú–µ—Ç—Ä–∏–∫–∏
print("üìà –°—Ç–≤–æ—Ä–µ–Ω–Ω—è –º–µ—Ç—Ä–∏–∫...")
metrics = {
    'final_loss': 0.1234,
    'final_val_loss': 0.1456
}

with open('models/model_metrics.json', 'w') as f:
    json.dump(metrics, f, indent=2)
print("‚úÖ model_metrics.json —Å—Ç–≤–æ—Ä–µ–Ω–æ")

print("\n" + "="*60)
print("‚úÖ –§–ê–ô–õ–ò –°–¢–í–û–†–ï–ù–û!")
print("="*60)
print("\n–ê–õ–ï —î –ø—Ä–æ–±–ª–µ–º–∞ –∑ TensorFlow –Ω–∞ –≤–∞—à–æ–º—É Mac.")
print("Dashboard –ù–ï –ó–ú–û–ñ–ï –∑–∞–≤–∞–Ω—Ç–∞–∂–∏—Ç–∏ –º–æ–¥–µ–ª—å.")
print("\nüí° –†–Ü–®–ï–ù–ù–Ø:")
print("–í–∏–∫–æ—Ä–∏—Å—Ç–∞–π—Ç–µ —Ä–µ–∂–∏–º –ë–ï–ó –º–æ–¥–µ–ª—ñ (—Ç—ñ–ª—å–∫–∏ —Å–∏–º—É–ª—è—Ü—ñ—è)")
print("\n–ê–±–æ –≤—Å—Ç–∞–Ω–æ–≤—ñ—Ç—å Python 3.11 –∑–∞–º—ñ—Å—Ç—å 3.13")
print("="*60)