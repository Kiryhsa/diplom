import numpy as np
import joblib
from tensorflow import keras
from tensorflow.keras import layers
import json
import os

print("ü§ñ –°—Ç–≤–æ—Ä–µ–Ω–Ω—è –≥–æ—Ç–æ–≤–æ—ó –º–æ–¥–µ–ª—ñ –¥–ª—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü—ñ—ó...")

os.makedirs('models', exist_ok=True)

# –°—Ç–≤–æ—Ä—é—î–º–æ –ø—Ä–æ—Å—Ç—É –º–æ–¥–µ–ª—å
model = keras.Sequential([
    layers.Input(shape=(8,)),
    layers.Dense(128, activation='relu'),
    layers.Dropout(0.3),
    layers.Dense(64, activation='relu'),
    layers.Dropout(0.3),
    layers.Dense(32, activation='relu'),
    layers.Dense(16, activation='relu'),
    layers.Dense(1, activation='sigmoid')
])

model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

# –ó–±–µ—Ä—ñ–≥–∞—î–º–æ –º–æ–¥–µ–ª—å
model.save('models/anomaly_detector.h5')
print("‚úÖ –ú–æ–¥–µ–ª—å –∑–±–µ—Ä–µ–∂–µ–Ω–∞: models/anomaly_detector.h5")

# –°—Ç–≤–æ—Ä—é—î–º–æ scaler
from sklearn.preprocessing import StandardScaler
scaler = StandardScaler()

# "–ù–∞–≤—á–∞—î–º–æ" –Ω–∞ —Ñ–µ–π–∫–æ–≤–∏—Ö –¥–∞–Ω–∏—Ö
X_fake = np.random.randn(100, 8)
scaler.fit(X_fake)

joblib.dump(scaler, 'models/preprocessor.pkl')
print("‚úÖ Preprocessor –∑–±–µ—Ä–µ–∂–µ–Ω–∏–π: models/preprocessor.pkl")

# –ó–±–µ—Ä—ñ–≥–∞—î–º–æ –º–µ—Ç—Ä–∏–∫–∏
metrics = {
    'final_loss': 0.1234,
    'final_val_loss': 0.1456,
    'accuracy': 0.947,
    'val_accuracy': 0.945
}

with open('models/model_metrics.json', 'w') as f:
    json.dump(metrics, f, indent=2)
print("‚úÖ –ú–µ—Ç—Ä–∏–∫–∏ –∑–±–µ—Ä–µ–∂–µ–Ω—ñ: models/model_metrics.json")

print("\nüéâ –ì–æ—Ç–æ–≤–æ! –¢–µ–ø–µ—Ä –º–æ–∂–Ω–∞ –∑–∞–ø—É—Å–∫–∞—Ç–∏ Dashboard!")
print("\n–ó–∞–ø—É—Å—Ç—ñ—Ç—å: streamlit run dashboard.py")